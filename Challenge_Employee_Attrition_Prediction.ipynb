{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKU2obxkKH8c"
   },
   "source": [
    "# Welcome the challenge notebook \n",
    "--- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvBVXrZHlWX8"
   },
   "source": [
    "In this challenge, you will work with a dataset provided by an HR manager who wants to predict which employees are at risk of leaving the company. The dataset contains four key performance indicators (KPIs) related to each employee. Your task is to use PySpark to build a machine learning model that can predict employee attrition and to identify which KPI is most strongly associated with attrition in this company.\n",
    "\n",
    "- Please note that the dataset is already clean and ready to be modeled. \n",
    "- The dataset only contains numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1xXctOSKf36"
   },
   "source": [
    "Installing pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bLd6XoJtJZP4",
    "outputId": "188408c7-4b28-4536-e5e3-35f00a392b32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/conda/lib/python3.10/site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gA6GqvzKpR6"
   },
   "source": [
    "Importing the needed modules and creating the spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (5.22.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly) (8.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from plotly) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->plotly) (3.0.9)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/conda/lib/python3.10/site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "id": "c-YsrJbjKptK",
    "outputId": "301acf21-7fde-47a0-b653-9ac8febbc2f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://9c14dbf85fb6:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Challenge</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x74e882d442b0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing spark session\n",
    "from pyspark.sql import SparkSession\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# data visualization modules \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px \n",
    "# pandas module \n",
    "import pandas as pd\n",
    "\n",
    "# pyspark data preprocessing modules\n",
    "from pyspark.ml.feature import  VectorAssembler, StandardScaler,StringIndexer\n",
    "\n",
    "# pyspark data modeling and model evaluation modules\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# creating the spark session\n",
    "spark = SparkSession.builder.appName(\"Challenge\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jn6fCpN5K5jb"
   },
   "source": [
    "Loading the `Challenge_dataset.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EKyTAZYKyTr",
    "outputId": "f56c16c7-3333-4223-d487-7332aa264d5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-------------------+-------------------+-------------------+---------------+\n",
      "|EmployeeID|              KPI1|               KPI2|               KPI3|               KPI4|CurrentEmployee|\n",
      "+----------+------------------+-------------------+-------------------+-------------------+---------------+\n",
      "|         0|1.4347155493478079| 0.8445778971189396| 1.2907117554310856|-1.4201273531837943|              1|\n",
      "|         1|0.8916245735832885| 0.8308158727699302| 1.0779750584283363|-1.0598957663940176|              1|\n",
      "|         2|-0.891158353098296|-0.9469681237741348|-1.1825287909456643| 1.1269205082112577|              0|\n",
      "|         3|1.2797294893867808| 1.6690888870054317| 1.9769417044649022| -1.797525912345404|              1|\n",
      "|         4|0.2576789316661615|0.34201906896710577|0.40342208520171396|-0.3653830886145554|              1|\n",
      "+----------+------------------+-------------------+-------------------+-------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.format('csv').option('header',True).option('inferSchema',True).load('Datasets/Challenge_dataset.csv')\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EmployeeID: integer (nullable = true)\n",
      " |-- KPI1: double (nullable = true)\n",
      " |-- KPI2: double (nullable = true)\n",
      " |-- KPI3: double (nullable = true)\n",
      " |-- KPI4: double (nullable = true)\n",
      " |-- CurrentEmployee: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5CQl_LEVHW3"
   },
   "source": [
    "Create the numerical feature vector using `Vector Assembler`.\n",
    "\n",
    "Hint: The numerical input features are the KPIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oLhqklGYVDsx",
    "outputId": "6cfc72bc-459d-449a-ae85-4aaef7b50274"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "num_features = [col for col in data.columns if col.startswith('KPI')]\n",
    "vecAssemb = VectorAssembler(inputCols = num_features, outputCol=\"num_feat_vector\")\n",
    "data = vecAssemb.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------------------+-------------------+--------------------+---------------+--------------------+\n",
      "|EmployeeID|               KPI1|                KPI2|               KPI3|                KPI4|CurrentEmployee|     num_feat_vector|\n",
      "+----------+-------------------+--------------------+-------------------+--------------------+---------------+--------------------+\n",
      "|         0| 1.4347155493478079|  0.8445778971189396| 1.2907117554310856| -1.4201273531837943|              1|[1.43471554934780...|\n",
      "|         1| 0.8916245735832885|  0.8308158727699302| 1.0779750584283363| -1.0598957663940176|              1|[0.89162457358328...|\n",
      "|         2| -0.891158353098296| -0.9469681237741348|-1.1825287909456643|  1.1269205082112577|              0|[-0.8911583530982...|\n",
      "|         3| 1.2797294893867808|  1.6690888870054317| 1.9769417044649022|  -1.797525912345404|              1|[1.27972948938678...|\n",
      "|         4| 0.2576789316661615| 0.34201906896710577|0.40342208520171396| -0.3653830886145554|              1|[0.25767893166616...|\n",
      "|         5|-1.1053563591145563| -1.2897283732181386|-1.5705804494874567|   1.464531035393369|              0|[-1.1053563591145...|\n",
      "|         6|-1.1428601324433787| -0.8267980776185402|-1.1670251067377129|  1.2205208819355595|              0|[-1.1428601324433...|\n",
      "|         7| 0.3271989171852082| -0.8475400819259096| -0.643469843461562|  0.2790482088327563|              1|[0.32719891718520...|\n",
      "|         8|-2.5247434318819506| -2.3355565540484857|-3.0370902011105416|   2.991370012909704|              0|[-2.5247434318819...|\n",
      "|         9|-1.3763798219688288|-0.10770226276789396|-0.6048085443112998|  0.9551634955968097|              0|[-1.3763798219688...|\n",
      "|        10|0.49001283582517563|  0.4780087023627603| 0.6117340472102887| -0.5949030783062104|              1|[0.49001283582517...|\n",
      "|        11| -1.400248912386222| -0.8574786472376928|-1.2896297703321804|  1.4052497943604432|              0|[-1.4002489123862...|\n",
      "|        12|-1.1068025418323348| -2.2693617983445393|-2.4543753184734025|  2.0333092160492106|              0|[-1.1068025418323...|\n",
      "|        13| 1.0192735392406644|  1.5365579264768816| 1.7613748622765615| -1.5517704737183866|              1|[1.01927353924066...|\n",
      "|        14| 2.0452906410683482| 0.03995384138060232| 0.7904642629377097|  -1.349755981020581|              1|[2.04529064106834...|\n",
      "|        15|-0.6373546763726241| -1.3465239260768618|  -1.44915817440957|  1.1939015366693337|              0|[-0.6373546763726...|\n",
      "|        16|-1.4449860803817232|  -1.518215144094145|-1.9018680113845745|  1.8172597705550035|              0|[-1.4449860803817...|\n",
      "|        17|-0.4829626475728436|-0.46386500830352584|-0.5963811631103025|  0.5821319228730506|              0|[-0.4829626475728...|\n",
      "|        18|-0.6916830522746196| -0.5414755200573603|-0.7433468348217778|  0.7624967506782165|              0|[-0.6916830522746...|\n",
      "|        19|-0.5253857933720771|  0.6384941373359674| 0.3818842503300117|-0.02932957196731...|              1|[-0.5253857933720...|\n",
      "+----------+-------------------+--------------------+-------------------+--------------------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2JgbGQtqOh2"
   },
   "source": [
    "Apply `Standard Scaler` to the numerical feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0DVLkyrWTF_",
    "outputId": "f31e17aa-7534-446a-f336-e0c470999bee"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "scaler = StandardScaler(inputCol = 'num_feat_vector', outputCol = 'num_feat_scaled', withStd=True, withMean=True)\n",
    "data = scaler.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-------------------+-------------------+-------------------+---------------+--------------------+--------------------+\n",
      "|EmployeeID|              KPI1|               KPI2|               KPI3|               KPI4|CurrentEmployee|     num_feat_vector|     num_feat_scaled|\n",
      "+----------+------------------+-------------------+-------------------+-------------------+---------------+--------------------+--------------------+\n",
      "|         0|1.4347155493478079| 0.8445778971189396| 1.2907117554310856|-1.4201273531837943|              1|[1.43471554934780...|[1.08218890600599...|\n",
      "|         1|0.8916245735832885| 0.8308158727699302| 1.0779750584283363|-1.0598957663940176|              1|[0.89162457358328...|[0.67319507945975...|\n",
      "|         2|-0.891158353098296|-0.9469681237741348|-1.1825287909456643| 1.1269205082112577|              0|[-0.8911583530982...|[-0.6693925230286...|\n",
      "+----------+------------------+-------------------+-------------------+-------------------+---------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPWtvnpsq0z6"
   },
   "source": [
    "Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J7MhYhqtq1rg",
    "outputId": "a04295f3-7678-4f64-bd05-ae3e7508533a"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "train, test = data.randomSplit([0.7,0.3], seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2813, 1187)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count(), test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMOG53waYjoI"
   },
   "source": [
    "Train your Decision Tree model. Use `maxDepth = 3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YUhsVtYQa5bm"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "dt = DecisionTreeClassifier(featuresCol=\"num_feat_scaled\", labelCol=\"CurrentEmployee\",\n",
    "                           maxDepth=3)\n",
    "model = dt.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKbBtzIlrT1x"
   },
   "source": [
    "Perform the prediction on the test set and calculate the accuracy using `BinaryClassificationEvaluator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Leo_RWmprjCj",
    "outputId": "5eb328b9-318d-4864-d628-084532c45a1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8901179103290812"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code here\n",
    "pred_test = model.transform(test)\n",
    "evalue = BinaryClassificationEvaluator(labelCol = \"CurrentEmployee\")\n",
    "auc_test = evalue.evaluate(pred_test,{evalue.metricName:\"areaUnderROC\"})\n",
    "auc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWwHgTp9sBp_"
   },
   "source": [
    "Apply the hyper paramter tuning to find the proper `maxDepth` for your decision tree from the `candidates` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p23wO0LAr0FG",
    "outputId": "4670523a-622f-45d1-9a2c-b27daa3d8782"
   },
   "outputs": [],
   "source": [
    "def evaluate_dt(mode_params):\n",
    "      test_accuracies = []\n",
    "      train_accuracies = []\n",
    "\n",
    "      for maxD in mode_params:\n",
    "        # train the model based on the maxD\n",
    "        decision_tree = DecisionTreeClassifier(featuresCol = 'num_feat_scaled', labelCol = 'CurrentEmployee', maxDepth = maxD)\n",
    "        dtModel = decision_tree.fit(train)\n",
    "\n",
    "        # calculating test error \n",
    "        predictions_test = dtModel.transform(test)\n",
    "        evaluator = BinaryClassificationEvaluator(labelCol='CurrentEmployee')\n",
    "        auc_test = evaluator.evaluate(predictions_test, {evaluator.metricName: \"areaUnderROC\"})\n",
    "        # recording the accuracy \n",
    "        test_accuracies.append(auc_test)\n",
    "\n",
    "        # calculating training error\n",
    "        predictions_training = dtModel.transform(train)\n",
    "        evaluator = BinaryClassificationEvaluator(labelCol='CurrentEmployee')\n",
    "        auc_training = evaluator.evaluate(predictions_training, {evaluator.metricName: \"areaUnderROC\"})\n",
    "        train_accuracies.append(auc_training)\n",
    "\n",
    "      return(test_accuracies, train_accuracies)  \n",
    "\n",
    "\n",
    "\n",
    "candidates = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "\n",
    "# write your code here\n",
    "test_accs, train_accs = evaluate_dt(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8AduBzoteop"
   },
   "source": [
    "Use a line chart to visualize the training and testing accuracy. <br>\n",
    "\n",
    "Hint: To visualize your data, convert the PySpark dataframe to pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "ISSL9xj7tKpK",
    "outputId": "ae33a67a-1f12-4fce-fd64-98c3223a5b6c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_17.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# write your code here\n",
    "df = pd.DataFrame()\n",
    "df['Candidates'] = candidates\n",
    "df['testAcc'] = test_accs\n",
    "df['trainAcc'] = train_accs\n",
    "px.line(df, x='Candidates', y=['testAcc','trainAcc']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLqPW95IwuE5"
   },
   "source": [
    "Train the decision tree using the proper `maxDepth` parameter.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Y39G2g9xtdwo"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "dt = DecisionTreeClassifier(featuresCol=\"num_feat_scaled\", labelCol=\"CurrentEmployee\",\n",
    "                           maxDepth=6)\n",
    "model = dt.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hN329Mg-xFc-"
   },
   "source": [
    "Use the `Feature Importance` to find the most important factor for the employee attrition using a barchart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "LDpAGaKJxEsK",
    "outputId": "2d8ac093-cd4f-4c15-e259-61fbdcf485c0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_19.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# write your code here\n",
    "feat_importance = model.featureImportances\n",
    "scores = []\n",
    "for i, score in enumerate(feat_importance):\n",
    "    scores.append(score)\n",
    "feat_Importance = pd.DataFrame(scores, columns=['Score'], index=num_features)\n",
    "px.bar(feat_Importance,y=\"Score\").show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
